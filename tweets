#!/usr/bin/env python3

# TODO
import nltk
import sys
import os
import helpers
from analyzer import Analyzer
from termcolor import colored

def main():

    # ensure proper usage
    if len(sys.argv) != 2:
        sys.exit("Usage: ./tweets @screen_name")

    # absolute paths to lists
    positives = os.path.join(sys.path[0], "positive-words.txt")
    negatives = os.path.join(sys.path[0], "negative-words.txt")
    
    #grab screen_name passed in at command line
    screen_name = sys.argv[1]
    
    #get tweets using get_user_timeline
    get_tweets = helpers.get_user_timeline(screen_name, 50)
    
    if get_tweets != None:
        #for each tweet in the list
        for tweet in get_tweets:
            total_score = 0
            score = 0
            #split each tweet into words
            tokenizer = nltk.tokenize.TweetTokenizer()
            tokens = tokenizer.tokenize(tweet)
            for token in tokens:
                # analyze word
                analyzer = Analyzer(positives, negatives)
                score = analyzer.analyze(token)
                total_score = total_score + score
            if total_score < 0:
                print(colored(total_score, "red"), end=" ")
                print(colored(tweet, "red"))
            elif total_score > 0:
                print(colored(total_score, "green"), end=" ")
                print(colored(tweet, "green"))
            else:
                print(colored(total_score, "yellow"), end=" ")
                print(colored(tweet, "yellow"))
            #print(colored(total_score, tweet)

                #if score > 0.0:
                #    print(colored(":)", "green"))
                #elif score < 0.0:
                #    print(colored(":(", "red"))
                #else:
                #    print(colored(":|", "yellow"))

if __name__ == "__main__":
    main()
